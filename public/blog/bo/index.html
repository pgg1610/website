<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <title>Pushkar Ghanekar | Bayesian Optimization using Gaussian Processes</title>
  <meta property="og:title" content="Pushkar Ghanekar | Bayesian Optimization using Gaussian Processes" />
  <meta property="og:image" content="/img/main_image.jpg" />
  <meta name="description" content="Minimal example explaining how bayesian optimization works">
  <meta property="og:description" content="Minimal example explaining how bayesian optimization works" />
  <meta name="author" content="Pushkar Ghanekar">
  
  <link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.0.0/css/bootstrap.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.0.0/css/bootstrap.min.css"></noscript>
  
  <link rel="preload" href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:100,200,300,400,500,600,700,800,900&display=swap" as="style" onload="this.onload=null;this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:100,200,300,400,500,600,700,800,900&display=swap"></noscript>
  <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i&display=swap" as="style" onload="this.onload=null;this.rel='stylesheet'">
      <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i&display=swap"></noscript>
  <link rel="preload" href="https://use.fontawesome.com/releases/v5.12.1/css/all.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.1/css/all.css"></noscript>
  <link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/devicons/1.8.0/css/devicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/devicons/1.8.0/css/devicons.min.css"></noscript>
  <link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/simple-line-icons/2.4.1/css/simple-line-icons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/simple-line-icons/2.4.1/css/simple-line-icons.min.css"></noscript>
  
  <link rel="preload" href="/css/resume.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/css/resume.css"></noscript>
  <link rel="preload" href="/css/tweaks.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/css/tweaks.css"></noscript>
  <link rel="preload" href="/css/resume-override.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/css/resume-override.css"></noscript>
  <meta name="generator" content="Hugo 0.69.0" />
  
   
  
</head>
<body id="page-top">
  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
  <a class="navbar-brand js-scroll-trigger" href="#page-top">
    <span class="d-block d-lg-none">Pushkar Ghanekar</span>
    <span class="d-none d-lg-block">
      <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="/img/main_image.jpg" alt="">
    </span>
  </a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarSupportedContent">
    <ul class="navbar-nav">
      <li class="nav-item">
        <a class="nav-link js-scroll-trigger" href="/#about">About</a>
      </li>
      
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="/#skills">Skills</a>
          </li>
      
      
      
      
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="/#Publications">Publications</a>
          </li>
      
      
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="/#experience">Experience</a>
          </li>
      
      
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="/#education">Education</a>
          </li>
      
      
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="/#blog">Blog</a>
          </li>
      
    </ul>
  </div>
</nav>

  <div class="container-fluid p-0">
    
<nav aria-label="breadcrumb">
  <ol  class="breadcrumb">
    





<li class="breadcrumb-item">
  <a href="/">Home</a>
</li>


<li class="breadcrumb-item">
  <a href="/blog/">Blog</a>
</li>


<li class="breadcrumb-item active">
  <a href="/blog/bo/">Bayesian Optimization using Gaussian Processes</a>
</li>

  </ol>
</nav>




<section class="resume-section p-3 p-lg-5 d-flex d-column content">
  <div class="my-auto">
    <h2 class="mb-0"><span class="text-primary">Bayesian Optimization using Gaussian Processes</span></h2>
    <p><a href="https://github.com/pgg1610/misc_notebooks/blob/master/Bayesian_optimisation/modular/demo.ipynb">Link to Jupyter Notebook</a></p>
    <ul>
<li>Notebook explaining the idea behind bayesian optimization alongside a small example showing its use. This notebook was adapted from Martin Krasser&rsquo;s <a href="http://krasserm.github.io/2018/03/21/bayesian-optimization/">blogpost</a></li>
<li>Good introductory write-up on Bayesian optimization <a href="https://distill.pub/2020/bayesian-optimization/">here</a></li>
<li>Nice lecture explaining the working of Gaussian Processes <a href="https://www.youtube.com/watch?v=92-98SYOdlY&amp;t=4827s">here</a></li>
</ul>
<h2 id="setup">Setup</h2>
<p>If <code>f</code> (objective function) is cheap to evaluate we can sample various points and built a potential surface however, if the <code>f</code> is expensive &ndash; like in case of first-principles electronic structure calculations, it is important to minimize the number of <code>f</code> calls and number of samples drawn from this evaluation. In that case, if an exact functional form for <code>f</code> is not available (that is, f behaves as a “black box”), what can we do?</p>
<p>Bayesian optimization proceeds by maintaining a probabilistic belief about f and designing a so called <strong><em>acquisition function</em></strong> to determine where to evaluate the function next. Bayesian optimization is particularly well-suited to global optimization problems where <code>f</code> is an expensive black-box function. The idea is the find &ldquo;global&rdquo; minimum with least number of steps. Incorporating prior beliefs about the underlying process and update the prior with samples draw from the model to better estimate the posterior. Model used for approximating the objective function is called the <strong><em>surrogate model</em></strong>.</p>
<h3 id="surrogate-model">Surrogate model</h3>
<p>A popular surrogate model applied for Bayesian optimization, although strictly not required, are Gaussian Processes (GPs). These are used to define a prior beliefs about the objective function. The GP posterior is cheap to evaluate and is used to propose points in the search space where sampling is likely to yield an improvement. Herein, we could substitute this for a ANNs or other surrogate models.</p>
<h3 id="acquisition-functions">Acquisition functions</h3>
<p>Used to propose sampling points in the search space. Trade-off between exploitation vs exploration. Exploitation == sampling where objective function value is high; exploration == where uncertainty is high. Both correspond to high <code>acquisition function</code> value. The goal is the maximize the acquisition value to determine next sampling point.</p>
<p>Popular acquisition functions:</p>
<ul>
<li>Maximum probability of improvement</li>
<li>Expected improvement</li>
<li>Lower/Upper confidence bound (UCB)</li>
</ul>
<p><em>1. Expected Improvement</em></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">EI</span>(X_new, gpr, delta, noisy, minimize_objective):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Compute the expected improvement at points X_new, from a Gaussian
</span><span style="color:#e6db74">    process surrogate model fit to observed data (X_sample, Y_sample).
</span><span style="color:#e6db74">            
</span><span style="color:#e6db74">    Arguments
</span><span style="color:#e6db74">    ---------
</span><span style="color:#e6db74">    X_new : array_like; shape (num_new_pts, input_dimension)
</span><span style="color:#e6db74">    Locations at which to compute expected improvement.
</span><span style="color:#e6db74">                
</span><span style="color:#e6db74">    gpr : GaussianProcessRegressor
</span><span style="color:#e6db74">    Regressor object, pre-fit to the sample data via the command
</span><span style="color:#e6db74">    gpr.fit(X_sample, Y_sample).
</span><span style="color:#e6db74">                
</span><span style="color:#e6db74">    delta : float
</span><span style="color:#e6db74">    Trade-off parameter for exploration vs. exploitation. Must be
</span><span style="color:#e6db74">    a non-negative value. A value of zero corresponds to pure ex-
</span><span style="color:#e6db74">    ploitation, with more exploration at larger values of delta.
</span><span style="color:#e6db74">                
</span><span style="color:#e6db74">    noisy : bool
</span><span style="color:#e6db74">    If True, assumes a noisy model and predicts the expected
</span><span style="color:#e6db74">    outputs at X_sample, rather than using Y_sample.
</span><span style="color:#e6db74">                
</span><span style="color:#e6db74">    minimize_objective : bool
</span><span style="color:#e6db74">    Designates whether the objective function is to be minimized
</span><span style="color:#e6db74">    or maximized. By default, minimization is assumed. In either
</span><span style="color:#e6db74">    case, the expected improvement is defined such that its value            
</span><span style="color:#e6db74">    should be maximized.
</span><span style="color:#e6db74">            
</span><span style="color:#e6db74">    Returns
</span><span style="color:#e6db74">    -------
</span><span style="color:#e6db74">    ei : np.ndarray; shape (num_points,)
</span><span style="color:#e6db74">    The expected improvement at each of the points in X_new.
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    <span style="color:#66d9ef">if</span> delta <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">0.0</span>:
        <span style="color:#66d9ef">raise</span> <span style="color:#a6e22e">ValueError</span>(<span style="color:#e6db74">&#34;Exploration parameter must be non-negative.&#34;</span>)

    <span style="color:#66d9ef">if</span> minimize_objective:
        best <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>min
        sign <span style="color:#f92672">=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">1.0</span>
    <span style="color:#66d9ef">else</span>:
        best <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>max
        sign <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.0</span>
            
    (mu, sigma) <span style="color:#f92672">=</span> gpr<span style="color:#f92672">.</span>predict(X_new, return_std <span style="color:#f92672">=</span> True)
    
    <span style="color:#66d9ef">if</span> (mu<span style="color:#f92672">.</span>ndim <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">and</span> mu<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">1</span>) <span style="color:#f92672">or</span> mu<span style="color:#f92672">.</span>ndim <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">2</span>:
        <span style="color:#66d9ef">raise</span> <span style="color:#a6e22e">RuntimeError</span>(<span style="color:#e6db74">&#34;Invalid shape for predicted &#34;</span>
                                   <span style="color:#e6db74">&#34;mean: </span><span style="color:#e6db74">%s</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> (mu<span style="color:#f92672">.</span>shape,))
    <span style="color:#66d9ef">else</span>:
        mu <span style="color:#f92672">=</span> mu<span style="color:#f92672">.</span>flatten()

    sigma <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>maximum(<span style="color:#ae81ff">1e-15</span>, sigma<span style="color:#f92672">.</span>flatten())
    <span style="color:#75715e"># Bump small variances to prevent divide-by-zero.</span>
            
    <span style="color:#66d9ef">if</span> noisy:
        mu_sample <span style="color:#f92672">=</span> gpr<span style="color:#f92672">.</span>predict(gpr<span style="color:#f92672">.</span>X_train_)
        best_y <span style="color:#f92672">=</span> best(mu_sample)
    <span style="color:#66d9ef">else</span>:
        best_y <span style="color:#f92672">=</span> best(gpr<span style="color:#f92672">.</span>y_train_)
            
    improvement <span style="color:#f92672">=</span> sign<span style="color:#f92672">*</span>(mu <span style="color:#f92672">-</span> best_y <span style="color:#f92672">+</span> delta)
    Z <span style="color:#f92672">=</span> improvement<span style="color:#f92672">/</span>sigma
    <span style="color:#66d9ef">return</span> improvement<span style="color:#f92672">*</span>stats<span style="color:#f92672">.</span>norm<span style="color:#f92672">.</span>cdf(Z) <span style="color:#f92672">+</span> sigma<span style="color:#f92672">*</span>stats<span style="color:#f92672">.</span>norm<span style="color:#f92672">.</span>pdf(Z)
</code></pre></div><p><em>2. Lower Confidence Bound</em></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">LCB</span>(X_new, gpr, sigma):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Compute the lower confidence bound at points X_new, from a Gaussian
</span><span style="color:#e6db74">    process surrogate model fit to observed data (X_sample, Y_sample).
</span><span style="color:#e6db74">            
</span><span style="color:#e6db74">    Arguments
</span><span style="color:#e6db74">    ---------
</span><span style="color:#e6db74">    X_new : array_like; shape (num_new_pts, input_dimension)
</span><span style="color:#e6db74">        Locations at which to compute confidence bound.
</span><span style="color:#e6db74">                
</span><span style="color:#e6db74">    gpr : GaussianProcessRegressor
</span><span style="color:#e6db74">        Regressor object, pre-fit to the sample data via the command
</span><span style="color:#e6db74">        gpr.fit(X_sample, Y_sample).
</span><span style="color:#e6db74">                
</span><span style="color:#e6db74">    sigma : float
</span><span style="color:#e6db74">        Trade-off parameter for exploration vs. exploitation. Must be
</span><span style="color:#e6db74">        a non-negative value. A value of zero corresponds to pure exploitation, with more                   exploration at larger values of sigma.
</span><span style="color:#e6db74">            
</span><span style="color:#e6db74">    Returns
</span><span style="color:#e6db74">    -------
</span><span style="color:#e6db74">    lcb : np.ndarray; shape (num_points,)
</span><span style="color:#e6db74">    The lower confidence bound at each of the points in X_new.
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    <span style="color:#66d9ef">if</span> sigma <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">0.0</span>:
        <span style="color:#66d9ef">raise</span> <span style="color:#a6e22e">ValueError</span>(<span style="color:#e6db74">&#34;Exploration parameter must be non-negative.&#34;</span>)
            
    (mean, std_dev) <span style="color:#f92672">=</span> gpr<span style="color:#f92672">.</span>predict(X_new, return_std <span style="color:#f92672">=</span> True)
    
    <span style="color:#66d9ef">if</span> (mean<span style="color:#f92672">.</span>ndim <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">and</span> mean<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">1</span>) <span style="color:#f92672">or</span> mean<span style="color:#f92672">.</span>ndim <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">2</span>:
        <span style="color:#66d9ef">raise</span> <span style="color:#a6e22e">RuntimeError</span>(<span style="color:#e6db74">&#34;Invalid shape for predicted &#34;</span>
                            <span style="color:#e6db74">&#34;mean: </span><span style="color:#e6db74">%s</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> (mean<span style="color:#f92672">.</span>shape,))
    <span style="color:#66d9ef">else</span>:
        mean <span style="color:#f92672">=</span> mean<span style="color:#f92672">.</span>flatten()
            
    <span style="color:#66d9ef">return</span> mean <span style="color:#f92672">-</span> sigma<span style="color:#f92672">*</span>std_dev
</code></pre></div><h3 id="objective-function">Objective function</h3>
<p>Objective function <code>f</code> we are interested in optimizing is the <code>Egg Carton</code> function which has quite peculiar shape, as seen in the schematic below. While there are local &lsquo;swiggles&rsquo; the overall function tends to a lower value around x = (4,6). We want to see if bayesian optimization can find this minimum value by optimizing not the ground function but rather a surrogate function which hypothetically would be &lsquo;cheaper&rsquo; to evaluate and optimize on.</p>
<p>The plot shown below has two main things: 1. The ground truth function which is the Egg carton function (shown by the black line) 2. The randomly sampled points which have some error built into them. Think of this like a sampling of surface with some error built-into the measuring the device, so it wont accurate sample the ground-truth function. We will use this &lsquo;noisy&rsquo; function for optimization.</p>
<p>Plot for the objective function:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">egg_carton</span>(x, f_noise <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>):
    x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>asarray(x)
    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>sin(<span style="color:#ae81ff">4.25</span><span style="color:#f92672">*</span>x) <span style="color:#f92672">+</span> <span style="color:#ae81ff">0.25</span><span style="color:#f92672">*</span>(x <span style="color:#f92672">-</span> <span style="color:#ae81ff">4.8</span>)<span style="color:#f92672">**</span><span style="color:#ae81ff">2.0</span> <span style="color:#f92672">+</span> f_noise <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>randn(<span style="color:#f92672">*</span>x<span style="color:#f92672">.</span>shape) 
</code></pre></div><p>Initial points are sampled from numpy&rsquo;s random number in a uniform distribution:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">num_sample_points <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>
noise_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.1</span>
generator <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>default_rng(<span style="color:#ae81ff">42</span>)
x_sample <span style="color:#f92672">=</span> generator<span style="color:#f92672">.</span>uniform(low, high, size <span style="color:#f92672">=</span> (num_sample_points, <span style="color:#ae81ff">1</span>))
y_sample <span style="color:#f92672">=</span> objective(x_sample, noise_)
</code></pre></div><p><img src="/img/bo/BO_New/test_function.png" alt="objective_function"></p>
<h3 id="bayesian-optimization">Bayesian optimization</h3>
<ul>
<li>Fit a surrogate function on initial points</li>
</ul>
<p><img src="/img/bo/BO_New/initial_gpr_eval.png" alt="initial_fit"></p>
<p>Bayesian optimization runs for few iterations.</p>
<p>For the inital points and the function value a GPR model as implemented in the <code>sklearn.gaussian_process.GaussianProcessRegressor</code> module is used. The prediction from the GPR is then used to optimize the acquisition function &ndash; Expected Improvement Criterion or Lower Confidence Bound.</p>
<h4 id="running-a-few-more-iterations">Running a few more iterations:</h4>
<p><img src="/img/bo/BO_New/final_iterations.png" alt="iter_final"></p>
<p>In total the noisy estimation of the ground-truth is conducted on 30 additional points. It is evident from the plot that most of those points are near the x = (4,6) since that is the minimum value region for the function.</p>

    <p class="mt-3">
    <ul class="tags">
    
      <li><a class="tag" href="/tags/python">Python</a></li>
    
      <li><a class="tag" href="/tags/optimization">Optimization</a></li>
    
      <li><a class="tag" href="/tags/bayesian-stats">Bayesian Stats</a></li>
    
</ul>

    </p>
  </div>
</section>


    <span style="color: #999999; font-size: 60%;">Nifty <a href="https://codepen.io/wbeeftink/pen/dIaDH">tech tag lists</a> from <a class="pen-owner-link" href="https://codepen.io/wbeeftink">Wouter Beeftink</a> </span>
    
  </div>
  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script async src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.0.0/js/bootstrap.bundle.min.js"></script>

  
  <script async src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
  
  <script async src="/js/resume.js"></script>
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-167983168-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-167983168-1');
  </script>
  

  
</body>
</html>
